"""
=================================================================================
TEST ADVERSARIAL ATTACK - Demo v·ªõi Webcam
=================================================================================
Code n√†y m·ªü webcam v√† demo vi·ªác t·∫•n c√¥ng ƒë·ªëi kh√°ng real-time.

T√≠nh nƒÉng:
- M·ªü Webcam m√°y t√≠nh
- Load model MobileNetV2/ResNet ƒë·ªÉ nh·∫≠n di·ªán
- B·∫≠t/T·∫Øt ch·∫ø ƒë·ªô t·∫•n c√¥ng b·∫±ng ph√≠m b·∫•m
- D√°n mi·∫øng adversarial_patch.png v√†o video webcam
- Hi·ªÉn th·ªã x√°c su·∫•t theo th·ªùi gian th·ª±c

Ph√≠m ƒëi·ªÅu khi·ªÉn:
- 't' : B·∫≠t/T·∫Øt Attack mode
- 'p' : Thay ƒë·ªïi v·ªã tr√≠ patch (center/follow mouse)
- 's' : Ch·ª•p screenshot
- 'r' : Reset v·ªÅ tr·∫°ng th√°i ban ƒë·∫ßu
- 'q' : Tho√°t

=================================================================================
"""

import torch
import torch.nn.functional as F
from torchvision import models, transforms
from PIL import Image
import cv2
import numpy as np
import requests
import os
import time

# ==========================================
# C·∫§U H√åNH
# ==========================================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
PATCH_PATH = "adversarial_patch.png"
TARGET_CLASS_IDX = 859  # Toaster (L√≤ n∆∞·ªõng)
PATCH_SCALE = 0.25      # Patch chi·∫øm 25% chi·ªÅu r·ªông m√†n h√¨nh

# ImageNet normalization
IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD = [0.229, 0.224, 0.225]

print("=" * 60)
print("üéÆ ADVERSARIAL ATTACK DEMO - Webcam Version")
print("=" * 60)
print(f"üñ•Ô∏è  Device: {DEVICE}")

# ==========================================
# 1. LOAD MODEL & LABELS
# ==========================================
print("\nüì¶ Loading model...")

# D√πng MobileNetV2 cho nh·∫π, ch·∫°y m∆∞·ª£t
model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1).to(DEVICE)
model.eval()
print("   ‚úÖ Loaded MobileNetV2")

# Optional: Load th√™m ResNet ƒë·ªÉ so s√°nh
try:
    model_resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1).to(DEVICE)
    model_resnet.eval()
    use_resnet = True
    print("   ‚úÖ Loaded ResNet50")
except:
    use_resnet = False

# T·∫£i labels
print("\nüìã Loading labels...")
try:
    url_labels = "https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json"
    labels = requests.get(url_labels, timeout=5).json()
    print("   ‚úÖ Loaded ImageNet labels")
except:
    labels = [f"class_{i}" for i in range(1000)]
    print("   ‚ö†Ô∏è Using default labels")

# Preprocess
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
])

# ==========================================
# 2. LOAD PATCH
# ==========================================
print(f"\nüé® Loading patch from '{PATCH_PATH}'...")

if os.path.exists(PATCH_PATH):
    patch_img = Image.open(PATCH_PATH).convert('RGB')
    print("   ‚úÖ Loaded adversarial patch")
else:
    print(f"   ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y '{PATCH_PATH}'!")
    print("   üìù H√£y ch·∫°y 'generate_patch.py' tr∆∞·ªõc ƒë·ªÉ t·∫°o patch")
    print("   üîß ƒêang t·∫°o patch placeholder...")
    
    # T·∫°o patch placeholder (rainbow gradient)
    arr = np.zeros((100, 100, 3), dtype=np.uint8)
    for i in range(100):
        for j in range(100):
            arr[i, j] = [
                int(127 + 127 * np.sin(i / 10)),
                int(127 + 127 * np.sin(j / 10)),
                int(127 + 127 * np.sin((i + j) / 15))
            ]
    patch_img = Image.fromarray(arr)

patch_np_original = np.array(patch_img)

# ==========================================
# 3. HELPER FUNCTIONS
# ==========================================

def predict(frame, model, with_patch=False, patch_np=None, patch_pos=None):
    """
    Ch·∫°y inference tr√™n frame.
    
    Args:
        frame: OpenCV frame (BGR)
        model: PyTorch model
        with_patch: C√≥ d√°n patch kh√¥ng
        patch_np: Numpy array c·ªßa patch
        patch_pos: Tuple (x, y) v·ªã tr√≠ d√°n
    
    Returns:
        Tuple (pred_idx, confidence, all_probs, processed_frame)
    """
    display_frame = frame.copy()
    process_frame = frame.copy()
    
    if with_patch and patch_np is not None and patch_pos is not None:
        h, w = frame.shape[:2]
        patch_h, patch_w = patch_np.shape[:2]
        x, y = patch_pos
        
        # ƒê·∫£m b·∫£o kh√¥ng v∆∞·ª£t qu√° bi√™n
        x = max(0, min(x, w - patch_w))
        y = max(0, min(y, h - patch_h))
        
        # D√°n patch l√™n frame ƒë·ªÉ x·ª≠ l√Ω
        process_frame[y:y+patch_h, x:x+patch_w] = patch_np
        
        # V·∫Ω khung ƒë·ªè tr√™n display frame
        cv2.rectangle(display_frame, (x, y), (x+patch_w, y+patch_h), (0, 0, 255), 3)
        display_frame[y:y+patch_h, x:x+patch_w] = patch_np
    
    # Convert BGR to RGB
    rgb_frame = cv2.cvtColor(process_frame, cv2.COLOR_BGR2RGB)
    pil_image = Image.fromarray(rgb_frame)
    
    # Preprocess v√† inference
    input_tensor = preprocess(pil_image).unsqueeze(0).to(DEVICE)
    
    with torch.no_grad():
        output = model(input_tensor)
        probs = F.softmax(output, dim=1)[0]
    
    pred_idx = probs.argmax().item()
    confidence = probs[pred_idx].item()
    
    return pred_idx, confidence, probs.cpu().numpy(), display_frame


def draw_info(frame, attack_mode, pred_idx, confidence, probs, fps):
    """V·∫Ω th√¥ng tin l√™n frame"""
    h, w = frame.shape[:2]
    
    # Background panel
    cv2.rectangle(frame, (5, 5), (350, 180), (0, 0, 0), -1)
    cv2.rectangle(frame, (5, 5), (350, 180), (100, 100, 100), 2)
    
    # Status
    status = "üî¥ ATTACK: ON" if attack_mode else "üü¢ ATTACK: OFF"
    color = (0, 0, 255) if attack_mode else (0, 255, 0)
    cv2.putText(frame, status, (15, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
    
    # FPS
    cv2.putText(frame, f"FPS: {fps:.1f}", (280, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
    
    # Prediction
    pred_label = labels[pred_idx][:20]
    cv2.putText(frame, f"AI Sees: {pred_label}", (15, 70), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
    cv2.putText(frame, f"Confidence: {confidence:.1%}", (15, 100), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
    
    # Target class probability
    target_prob = probs[TARGET_CLASS_IDX]
    target_label = labels[TARGET_CLASS_IDX][:15]
    cv2.putText(frame, f"Target ({target_label}): {target_prob:.1%}", (15, 130), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (100, 200, 255), 1)
    
    # Progress bar cho target probability
    bar_width = int(300 * target_prob)
    cv2.rectangle(frame, (15, 145), (15 + bar_width, 165), (100, 200, 255), -1)
    cv2.rectangle(frame, (15, 145), (315, 165), (100, 100, 100), 2)
    
    # Instructions
    cv2.putText(frame, "Press 't' to toggle attack | 'q' to quit", (15, h - 15),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
    
    return frame


def draw_comparison(frame, results_clean, results_attack, attack_mode):
    """V·∫Ω so s√°nh k·∫øt qu·∫£ Clean vs Attack"""
    h, w = frame.shape[:2]
    
    if not attack_mode:
        return frame
    
    # Panel b√™n ph·∫£i
    panel_x = w - 300
    cv2.rectangle(frame, (panel_x, 5), (w - 5, 120), (0, 0, 0), -1)
    cv2.rectangle(frame, (panel_x, 5), (w - 5, 120), (100, 100, 100), 2)
    
    cv2.putText(frame, "COMPARISON", (panel_x + 10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
    
    # Clean result
    clean_label = labels[results_clean[0]][:12]
    cv2.putText(frame, f"Clean: {clean_label} ({results_clean[1]:.0%})", 
                (panel_x + 10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
    
    # Attack result
    attack_label = labels[results_attack[0]][:12]
    cv2.putText(frame, f"Attack: {attack_label} ({results_attack[1]:.0%})", 
                (panel_x + 10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
    
    # Success indicator
    if results_clean[0] != results_attack[0]:
        cv2.putText(frame, "SUCCESS!", (panel_x + 10, 105), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
    
    return frame


# ==========================================
# 4. MAIN LOOP
# ==========================================
print("\nüé• Opening webcam...")

cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print("‚ùå Cannot open camera!")
    print("   Th·ª≠ v·ªõi camera ID kh√°c (1, 2...) ho·∫∑c ki·ªÉm tra k·∫øt n·ªëi")
    exit()

# Set resolution
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

print("   ‚úÖ Webcam opened successfully")
print("\n" + "=" * 60)
print("üéÆ CONTROLS:")
print("   't' - Toggle Attack ON/OFF")
print("   's' - Save screenshot")
print("   'r' - Reset")
print("   'q' - Quit")
print("=" * 60)
print("\nüöÄ Starting demo... (Press 'q' to quit)\n")

# State variables
attack_mode = False
frame_count = 0
start_time = time.time()
fps = 0

# Resize patch d·ª±a tr√™n k√≠ch th∆∞·ªõc webcam
ret, test_frame = cap.read()
if ret:
    frame_h, frame_w = test_frame.shape[:2]
    patch_size = int(frame_w * PATCH_SCALE)
    patch_np = cv2.resize(patch_np_original, (patch_size, patch_size))
    patch_pos = ((frame_w - patch_size) // 2, (frame_h - patch_size) // 2)
    print(f"   Patch size: {patch_size}x{patch_size} pixels")
    print(f"   Patch position: center ({patch_pos})")

# Main loop
while True:
    ret, frame = cap.read()
    if not ret:
        print("‚ùå Cannot read frame!")
        break
    
    # Mirror effect (optional - comment out if not needed)
    frame = cv2.flip(frame, 1)
    
    frame_count += 1
    
    # Calculate FPS
    elapsed = time.time() - start_time
    if elapsed > 0:
        fps = frame_count / elapsed
    
    # Get predictions
    # Clean prediction (kh√¥ng c√≥ patch)
    pred_clean, conf_clean, probs_clean, _ = predict(frame, model)
    
    # Attack prediction (c√≥ patch n·∫øu attack_mode = True)
    pred_attack, conf_attack, probs_attack, display_frame = predict(
        frame, model, 
        with_patch=attack_mode, 
        patch_np=patch_np, 
        patch_pos=patch_pos
    )
    
    # Ch·ªçn k·∫øt qu·∫£ ƒë·ªÉ hi·ªÉn th·ªã
    if attack_mode:
        pred_idx, confidence, probs = pred_attack, conf_attack, probs_attack
    else:
        pred_idx, confidence, probs = pred_clean, conf_clean, probs_clean
        display_frame = frame.copy()
    
    # Draw info
    display_frame = draw_info(display_frame, attack_mode, pred_idx, confidence, probs, fps)
    
    # Draw comparison (khi attack mode ON)
    display_frame = draw_comparison(
        display_frame, 
        (pred_clean, conf_clean), 
        (pred_attack, conf_attack), 
        attack_mode
    )
    
    # Show
    cv2.imshow('Adversarial Attack Demo - Press q to quit', display_frame)
    
    # Handle keys
    key = cv2.waitKey(1) & 0xFF
    
    if key == ord('q'):
        print("\nüëã Exiting...")
        break
    
    elif key == ord('t'):
        attack_mode = not attack_mode
        status = "ON üî¥" if attack_mode else "OFF üü¢"
        print(f"   Attack mode: {status}")
    
    elif key == ord('s'):
        filename = f"screenshot_{int(time.time())}.png"
        cv2.imwrite(filename, display_frame)
        print(f"   üì∏ Saved: {filename}")
    
    elif key == ord('r'):
        attack_mode = False
        frame_count = 0
        start_time = time.time()
        print("   üîÑ Reset!")

# Cleanup
cap.release()
cv2.destroyAllWindows()

print("\n" + "=" * 60)
print("‚úÖ Demo ended successfully!")
print("=" * 60)
